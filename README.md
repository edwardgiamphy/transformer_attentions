# transformer_attentions
Project to initialize a transformer-based model with different types of attention.
